{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import scipy.fftpack as fft\n",
    "import seaborn as sns\n",
    "# from mpl_toolkits import basemap\n",
    "import geopandas\n",
    "import cartopy\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 77\n",
    "from shapely.geometry import Point\n",
    "import shapely.ops as shops\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename, usecols=[2, 5, 8, 19, 20], dtype={'Primary Type': str, 'Arrest': bool, 'Latitude' : float, 'Longitude' : float}, **kwargs):\n",
    "\n",
    "    data = pd.read_csv(filename, usecols=usecols, dtype=dtype, quotechar='\"', index_col='Date', **kwargs)\n",
    "    data.index = pd.to_datetime(data.index, format='%m/%d/%Y %I:%M:%S %p')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_counts(crime_df, crime_type=None):\n",
    "    \"\"\"Add the counts by function of hour, day, month, and year\n",
    "    \n",
    "    If crime_type is None, then all crimes. Otherwise, for crime_type only\"\"\"\n",
    "    \n",
    "    crime_count_dict = {}\n",
    "    \n",
    "    if crime_type is not None and str.lower(crime_type) != 'all':\n",
    "        crime_df = crime_df[crime_df['Primary Type'] == str.upper(crime_type)]\n",
    "    \n",
    "    if len(crime_df) == 0:\n",
    "        raise KeyError('Invalid crime type')\n",
    "    \n",
    "    crime_count_dict['hour'] = crime_df.index.hour.value_counts().astype(float)\n",
    "    crime_count_dict['weekday'] = crime_df.index.weekday.value_counts().astype(float)\n",
    "    crime_count_dict['day'] = crime_df.index.day.value_counts().astype(float)\n",
    "    crime_count_dict['month'] = crime_df.index.month.value_counts().astype(float)\n",
    "    crime_count_dict['year'] = crime_df.index.year.value_counts().astype(float)\n",
    "    \n",
    "    return crime_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counts(counts, ax, weights=None, bar=True, do_err=False, **kwargs):\n",
    "    \"\"\"Provide bar position and heights for crime counts\n",
    "    \n",
    "    if weights is not None, weightsalize \n",
    "    If bar false, do a line plot\n",
    "    \"\"\"\n",
    "    xs = counts.index\n",
    "    vals = counts.values / counts.values.sum()\n",
    "    \n",
    "    if weights is not None:\n",
    "        try:\n",
    "            vals *= weights\n",
    "        except TypeError:\n",
    "            if weights.lower() == 'month':\n",
    "                weights = 1. / np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]) * 30. \n",
    "                #technically Feb is 28.25?\n",
    "            elif weights.lower() == 'day':\n",
    "                weights = np.ones(31)\n",
    "                weights[30] = 12./7\n",
    "                weights[29] = 12./11\n",
    "                weights[28] = 12./11\n",
    "            else:\n",
    "                print(f'Unrecognized weights: {weights}')\n",
    "                weights = np.ones(len(xs))\n",
    "            assert len(weights) == len(xs)\n",
    "            vals *= weights\n",
    "    if bar:\n",
    "        ax.bar(xs, vals, **kwargs)\n",
    "    else:\n",
    "        if do_err:\n",
    "            ax.errorbar(np.sort(xs), vals[np.argsort(xs)], yerr=np.sqrt(counts.values)/counts.values.sum(), **kwargs)\n",
    "        else:\n",
    "            ax.plot(np.sort(xs), vals[np.argsort(xs)], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_crime_map(crime_df, geo_df, census_df, year, crime_type, cmap='Blues', annotate=False,\n",
    "                  num_annotations=(3, 3), annot_colors=('black', 'black')):\n",
    "    \"\"\"Plot the crime rate by neighborhood\n",
    "    \n",
    "    crime_df : the crime dataframe\n",
    "    geo_df : the geopandas dataframe, for drawing the map\n",
    "    census_df : the census dataframe\n",
    "    year : either one year or a range of years, inclusively, (min_year, max_year)\n",
    "    crime_type : the type of crime to consider\n",
    "    cmap (default 'Blues') : the colormap to use\n",
    "    annotate (default False) : whether to label the highest and/or lowest crime neighborhoods, using\n",
    "        the remaining arguments as guide\n",
    "    num_annotations (default (3, 3)) : 2-tuple with (num_low, num_high), the number of neighborhoods to\n",
    "        label with the lowest and highest crime rates, respectively\n",
    "    annot_colors (default ('black', 'black')) : 2-tuple with colors to use to plot low and high neighborhoods\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        a = len(year)\n",
    "    except TypeError:\n",
    "        year = [year]\n",
    "    \n",
    "    if len(year) == 1:\n",
    "        subview = crime_df.loc[crime_df['Year'] == year[0]]\n",
    "    elif len(year) == 2:\n",
    "        subview = crime_df.loc[(crime_df['Year'] >= year[0]) & (crime_df['Year'] <= year[1])]\n",
    "    else:\n",
    "        raise ValueError('Too many years!')\n",
    "        \n",
    "    neighborhood_counts = (subview[subview['Primary Type'] == crime_type.upper()]['Community Area']\n",
    "                                                .value_counts(sort=False))\n",
    "    neighborhood_counts = neighborhood_counts.reindex(index=geo_df['area_num_1'].astype(int), fill_value=0)\n",
    "    neighborhood_rates = (1e5 * neighborhood_counts / census_df['Total Population'] / len(subview['Year']\n",
    "                                                .value_counts()))\n",
    "\n",
    "    cmap1 = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    cmap1.set_clim(0, neighborhood_rates.max())\n",
    "\n",
    "    ax = geo_df.plot(edgecolor='k', \n",
    "                    facecolor=cmap1.to_rgba(neighborhood_rates.loc[geo_df['area_num_1'].astype(int)]), \n",
    "                    figsize=(10, 10))\n",
    "    \n",
    "    fig = ax.get_figure()\n",
    "    cax = fig.add_axes([0.95, 0.15, 0.025, 0.7])\n",
    "    cbar = fig.colorbar(cmap1, cax=cax)\n",
    "    if len(year) > 1:\n",
    "        year_label = f'{year[0]} to {year[1]}'\n",
    "    else:\n",
    "        year_label = f'{year[0]}'\n",
    "    cbar.set_label(f'{crime_type.title()} per 100k people, ' + year_label, rotation=270, fontsize=20, labelpad=20)\n",
    "    ax.set_xlim([-88, -87.5])\n",
    "    ax.set_ylim([41.6, 42.05])\n",
    "    \n",
    "    if annotate:\n",
    "        # lowest crime rate not necessarily unique if there are multiple zeros\n",
    "        annotate_inds = []\n",
    "        annotate_inds += list(np.arange(num_annotations[0]))\n",
    "        annotate_inds += list(np.arange(-num_annotations[1], 0))\n",
    "        to_annotate = neighborhood_rates.sort_values().iloc[annotate_inds]\n",
    "        if len(to_annotate) > 0:\n",
    "            # location of neighborhood centers\n",
    "            xys = np.array([[geo_df[geo_df['area_num_1'] == neighborhood].centroid.x.values[0], \n",
    "                   geo_df[geo_df['area_num_1'] == neighborhood].centroid.y.values[0]]\n",
    "                   for neighborhood in to_annotate.index])\n",
    "            second_leg = []\n",
    "            for i, (x, y) in enumerate(xys):\n",
    "    #             ax.text(x, y, geo_df[geo_df['area_num_1'] == to_annotate.index[i]]['community'].values[0].title())\n",
    "                ax.scatter(x, y, marker=f'${to_annotate.index[i]}$', \n",
    "                                  color=annot_colors[0 if i<num_annotations[0] else 1], \n",
    "                                  s=50 if to_annotate.index[i] < 10 else 100)\n",
    "                # this one is just for the legend, to make sure the marker is black and legible\n",
    "                scat = ax.scatter([], [], marker=f'${to_annotate.index[i]}$', color='black',\n",
    "                                  s=100 if to_annotate.index[i] < 10 else 200,\n",
    "                                  label=geo_df[geo_df['area_num_1'] \n",
    "                                   == to_annotate.index[i]]['community'].values[0].title()\n",
    "                          + f', {neighborhood_rates.loc[to_annotate.index[i]]:.1f}')\n",
    "                if i == num_annotations[0] - 1:\n",
    "                    leg = ax.legend(loc='center left', title=f'Lowest Crime Area\\nID Number, Name, {crime_type.title()}/100k',\n",
    "                                   fontsize=12, title_fontsize=12)\n",
    "                    ax.add_artist(leg)\n",
    "                    continue\n",
    "                if i >= num_annotations[0]:\n",
    "                    second_leg.append(scat)\n",
    "                if i == len(xys) - 1:\n",
    "                    ax.legend(handles=second_leg, loc='lower left', \n",
    "                              title=f'Highest Crime Area\\nID Number, Name, {crime_type.title()}/100k',\n",
    "                             fontsize=12, title_fontsize=12)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nrows = None\n",
    "filename = '/home/elaad/Documents/Fun/DatAnalysis/datasets/Crimes_-_2001_to_present.csv'\n",
    "crimedata = read_data(filename, nrows=nrows, usecols=None, dtype=None)\n",
    "print(len(crimedata[crimedata.Longitude <= -90]))\n",
    "crimedata = crimedata[crimedata.Longitude > -90] # getting rid of a few unexpected outliers beyond the city limits\n",
    "crimedata.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_dat = pd.read_excel('/home/elaad/Documents/Fun/DatAnalysis/datasets/CCASF12010CMAP.xlsx',\n",
    "                          index_col=1, header=1, skiprows=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "What are the most common crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimedata['Primary Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(10, 10)\n",
    "crimedata['Primary Type'].value_counts().plot(kind='bar', ax=ax)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, thefts are the most common crime, followed by battery. This is not terribly surprising. Of, say, thefts, what are the most common descriptors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(10, 10)\n",
    "crimedata[crimedata['Primary Type'] == 'THEFT']['Description'].value_counts().plot(kind='bar', ax=ax)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common theft description is \\\\$500 and under, followed by over \\\\$500; small amounts are more common than large. For Financial ID Theft, however, it is the other way around, with higher amounts more common.\n",
    "\n",
    "Retail theft has one reported incidence; I should look into this. Under-reporting, or inconsistent descriptor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crimes as a function of time and date\n",
    "\n",
    "Some assumptions certainly go into the believability of these plots.\n",
    "For example:\n",
    "* Listed information---particularly dates and times---are accurate (the overabundance of crimes on the first of the month casts doubt on this assumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_counts = {}\n",
    "for crime_type in ['all', 'homicide', 'theft']:\n",
    "    crime_counts[crime_type] = add_counts(crimedata, crime_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for time_interval in crime_counts['all']:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(7, 5)\n",
    "    for crime_type, color, hatch in zip(crime_counts, [f'C{i}' for i in range(len(crime_counts))],\n",
    "                                ['//', '\\\\\\\\', '--']):\n",
    "        plot_counts(crime_counts[crime_type][time_interval], ax, weights=time_interval, bar=False, do_err=True,\n",
    "                    label=crime_type.capitalize(), color=color,)# alpha=1./len(crime_counts),)\n",
    "#                     hatch=hatch)\n",
    "    ax.legend(loc='best', fontsize=14)\n",
    "    ax.set_xlabel(time_interval.capitalize(), fontsize=18)\n",
    "    ax.set_ylabel('N/N$_\\mathrm{tot}$', fontsize=18)\n",
    "    ax.set_ylim([0, ax.set_ylim()[-1] * 1.2])\n",
    "    if time_interval == 'year':\n",
    "        ax.set_xticklabels([str(year) for year in np.arange(2001, 2021, 2)])\n",
    "        ax.set_xticks(np.arange(2001, 2021, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few interesting things to note here. Crimes generally seem to be least frequent around 5 AM, while homicides bottom out around 7 AM. Homicides also seem to peak a bit later than most crimes. Thefts, on the other hand, peak in the afternoon (except for a single spike around noon, which I will assume for now comes from thefts around the lunch hour. To test this I should see which specific types of theft are contributing to the spike). All of these observations are consistent with a general idea that most crimes require people to be around, while homicides occure when people *aren't* around.\n",
    "\n",
    "There aren't strong trends with day of the week, except for a weekday/weekend divide. Homicides are less common on weekdays and more common on weekends, while other crimes are generally more common during the week. Future work will require separating crimes geographically. How much of this trend comes from crimes being concentrated in business areas?\n",
    "\n",
    "For day of the month, I have weighted the histograms so that long months have their extra days' counts proportionately increased. With the exception of the first and last day of the month, variations look like noise. I assume (for now) that the differences in the first/last days are reporting biases of some sort.\n",
    "\n",
    "For month of year, I have also weighted months by their length, so I have upweighted February and downweighted long months.\n",
    "\n",
    "Crime generally has gone down over the last 19 years, almost by a factor of 2. The decline may be leveling, however. Starting in 2015, as well, murders spiked significantly, though perhaps they are returning again to their previous levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where do crimes occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf = geopandas.read_file('../datasets/Boundaries_Community_Areas/')\n",
    "geodf['area_num_1'] = geodf['area_num_1'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_crime_map(crimedata, geodf, census_dat, (2015, 2019), 'homicide', cmap='Blues', \n",
    "               annotate=True, num_annotations=(5, 5), annot_colors=('black', 'white'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do -- make a gif of this over time (murder rate per year...)\n",
    "\n",
    "Anyway -- here were the neighborhoods with the most murders in 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do crimes behave as a Poisson process? - Not Done\n",
    "\n",
    "Let's use 2007 as a \"typical\" year, since it's in the middle of a steady homicide rate.\n",
    "\n",
    "Caveat -- assumes accurate reporting times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crimes2007 = crimedata[crimedata.index.year==2007]\n",
    "for crimetype in ['HOMICIDE', 'THEFT', 'BATTERY']:\n",
    "    subset2007 = crimes2007[crimes2007['Primary Type']==crimetype]\n",
    "    subset_mean = len(subset2007)/365.0\n",
    "    print('There were an average of {:.2f} '.format(subset_mean)+crimetype+' crimes per day in 2007')\n",
    "    subset_counts2007 = subset2007.index.dayofyear.value_counts()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    if len(subset2007)>1000.0:\n",
    "        bins = np.arange(subset_counts2007.min()-1.5, subset_counts2007.max()+1.5, 2.0)\n",
    "    else:\n",
    "        bins = np.arange(subset_counts2007.min()-1.5, subset_counts2007.max()+1.5, 1.0)\n",
    "    ax.hist(subset_counts2007.values, bins=bins, label='Actual Counts')\n",
    "    ax.plot(bins+0.5, 365.0*ss.poisson.pmf(bins+0.5, subset_mean), 'o', label='Poisson')\n",
    "    ax.set_xlabel(crimetype+' Per Day')\n",
    "    ax.set_ylabel('Count')\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT - Not done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_days = (crimedata.index - pd.to_datetime('Jan 01 2001')).days.value_counts().sort_index()\n",
    "homicide_days = (crimedata[crimedata['Primary Type'] == 'HOMICIDE'].index - \n",
    "                 pd.to_datetime('Jan 01 2001')).days.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(crime_days/crime_days.sum())\n",
    "ax.plot(homicide_days/homicide_days.sum()+0.00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "homicide_fft = fft.fft(homicide_days.values)\n",
    "homicide_freq = fft.fftfreq(len(homicide_days))\n",
    "crime_fft = fft.fft(crime_days.values)\n",
    "crime_freq = fft.fftfreq(len(crime_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(homicide_freq, np.abs(homicide_fft))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak in one year period, as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "# plt.plot(crime_freq, np.abs(crime_fft))\n",
    "plt.plot(np.linspace(0, 1, len(crime_fft))**-1 / 365, np.abs(crime_fft))\n",
    "plt.yscale('log')\n",
    "# plt.loglog([], [])\n",
    "plt.xlim([0, 4])\n",
    "plt.axvline(1, color='red', ls='--')\n",
    "plt.axvline(0.5, color='red', ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "filt_crime_fft = crime_fft.copy()\n",
    "filt_crime_fft[np.abs(filt_crime_fft) < 75000] = 0\n",
    "plt.plot(np.linspace(0, len(crime_days)/365, len(crime_days)), crime_days)\n",
    "plt.plot(np.linspace(0, len(crime_days)/365, len(crime_days)), fft.ifft(filt_crime_fft))\n",
    "\n",
    "plt.plot(np.linspace(0, len(crime_days)/365, len(crime_days)), crime_days - fft.ifft(filt_crime_fft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sigma):\n",
    "    x = np.array(x)\n",
    "    return 1. / np.sqrt((2 * np.pi * sigma)) * np.exp(-(x - mu)**2 / (2 * sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(crime_days)\n",
    "plt.plot(np.convolve(crime_days, gaussian(np.arange(-20, 20, 1), 0, 7))) #gaussian smoothing with 1 week sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chicago] *",
   "language": "python",
   "name": "conda-env-chicago-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "139px",
    "width": "284px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
